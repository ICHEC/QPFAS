{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QPFAS: Dask Workflow\n",
    "Here we illustrate the Dask workflow by running a set of experiments defined by the yaml file `H2_exp_input.yml` which is in the `experiment_inputs` directory. The results will be saved in the file `H2_exp_output.json`.\n",
    "\n",
    "This set of experiemnts is for H2 with the VQE run to determine the ground-state energy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin, let's view the input yml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat experiment_inputs/H2_exp_input.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will result in 6 VQE runs since we have 2 qubit transformations and 3 optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import qpfas\n",
    "from dask.distributed import get_task_stream  # necessary for the timings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = qpfas.workflow.DaskDAG.create_client(dask_scheduler_uri=\"tcp://dask-scheduler:8786\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define experiments from YAML, generate DAGs from YAML, execute using Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YAML_FILE = os.path.join(os.getcwd(), 'experiment_inputs','H2_exp_input.yml')\n",
    "graph, keys_to_gather, exp_params, dag_nodes = qpfas.workflow.EfficientDAG.load_from_yaml(YAML_FILE)\n",
    "\n",
    "print(\"Number of Experiments:\", len(exp_params))\n",
    "\n",
    "print(\"\\nDAG Nodes:\")\n",
    "for i in dag_nodes:\n",
    "    print(f\"{i}: {dag_nodes[i]}\")\n",
    "    \n",
    "print(\"\\nKeys Gathered:\")\n",
    "print(keys_to_gather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qpfas.workflow.DaskDAG.visualize_dag(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View single DAG for all experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute DAG and get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = qpfas.utils.get_all_metadata()\n",
    "\n",
    "global_start_timestamp = qpfas.utils.get_datetime_now()\n",
    "with get_task_stream() as ts:  # necessary for timing logs\n",
    "    results = qpfas.workflow.DaskDAG.get(client, graph, keys_to_gather)\n",
    "global_end_timestamp = qpfas.utils.get_datetime_now()\n",
    "\n",
    "metadata['global_start_timestamp'] = global_start_timestamp\n",
    "metadata['global_end_timestamp'] = global_end_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get timing logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = qpfas.workflow.EfficientDAG.get_timing_logs(ts, exp_params, results, metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine dictionaries (params & results) and save to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qpfas.workflow.EfficientDAG.write_to_file(\"H2_exp_output\", exp_params, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -100 H2_exp_output.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
